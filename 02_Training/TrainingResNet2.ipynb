{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "import os.path\n",
    "from ipywidgets import interact, widgets\n",
    "from IPython.display import Image, display, HTML\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listdir_nohidden(path):\n",
    "    return glob.glob(os.path.join(path, '*'))\n",
    "style = {'description_width': 'initial'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECTRUM_IMAGES_ROOT='../GeneratedData/'\n",
    "SPECTRUM_IMAGES_CLASSESDropdown= widgets.Dropdown(options=listdir_nohidden(SPECTRUM_IMAGES_ROOT), description='Source for Training Data:',style=style)\n",
    "\n",
    "display(SPECTRUM_IMAGES_CLASSESDropdown)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data set\n",
    "If test set is not defined previously, this function pulls a test set from the training set using a 80/20%split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECTRUM_IMAGES_CLASSES_TRAIN = SPECTRUM_IMAGES_CLASSESDropdown.value\n",
    "SPECTRUM_IMAGES_CLASSES_TEST = ''\n",
    "INPUT_RESOLUTION = 224\n",
    "    \n",
    "transform = transforms.Compose(\n",
    "    [transforms.Resize(INPUT_RESOLUTION),\n",
    "    transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset=[]\n",
    "testset=[]\n",
    "NoTestSet=False\n",
    "full_dataset=None\n",
    "if len(SPECTRUM_IMAGES_CLASSES_TEST)==0:\n",
    "    print(\"Using one data set and separating them with an 80%/20% split\")\n",
    "    full_dataset = torchvision.datasets.ImageFolder(root=SPECTRUM_IMAGES_CLASSES_TRAIN, transform=transform)\n",
    "    full_DataLoader = torch.utils.data.DataLoader(full_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    trainset, testset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "    NoTestSet=True\n",
    "else:\n",
    "    print(\"Using pre-seperated test and training data sets!\")\n",
    "    trainset = torchvision.datasets.ImageFolder(root=SPECTRUM_IMAGES_CLASSES_TRAIN, transform=transform)\n",
    "    testset = torchvision.datasets.ImageFolder(root=SPECTRUM_IMAGES_CLASSES_TEST, transform=transform)\n",
    "    \n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=False, num_workers=2)\n",
    "classes=None\n",
    "if(NoTestSet):\n",
    "    classes = full_DataLoader.dataset.classes\n",
    "else:\n",
    "    classes = trainloader.dataset.classes\n",
    "\n",
    "print(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview sample training images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell takes an entire training batch of images and displays them with their respective labels. Have a look and verify that indeed you see spectrograph images that look similar to what you saw earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting some random training images and showing them\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "for i in range(trainloader.batch_size):\n",
    "    imshow(images[i])\n",
    "    print(classes[labels[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify use of Graphics Card (if there is one) and use ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet18(pretrained=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained model \n",
    "The model '../Models/MainModelUrban.pth' was trained on the UrbanSound dataset; other models could be specified instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelData = torch.load('../Models/MainModelUrban.pth',map_location='cpu')\n",
    "model.load_state_dict(ModelData['model'])\n",
    "# IncompatibleKeys(missing_keys=[], unexpected_keys=[]) Means it was succesfull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cutting off the head\n",
    "In the following cell, the setting 'param.requires_grad = False' is **the** function that is telling the network to only retrain the last layer. If you set this parameter to True, the training will take much longer, but hopefully be better at predicting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.fc = nn.Linear(512, len(classes)) # otherwise change it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move model to GPU (if there is a GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('device is', device)\n",
    "if device.type=='cuda':\n",
    "    model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "train_epoch_losses=[]\n",
    "test_epoch_losses=[]\n",
    "epoch=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the network on the training dataset\n",
    "for i in range(5):  # loop over the dataset multiple (5) times \n",
    "    epoch+=1\n",
    "    print(\"Starting epoch:\",epoch)\n",
    "    epochLoss=0.0\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        #print(\"Running Batches\",i)\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        if device.type=='cuda':\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        if((i+i)%200==0):\n",
    "            if(i>0):\n",
    "                print('Processed images:',i*trainloader.batch_size,'. Running Timer @ {:.2f}sec.'.format(time.time()-t0))\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epochLoss+=loss.item()\n",
    "        #break;\n",
    "    \n",
    "    model.eval()\n",
    "    testLoss=0\n",
    "    print(\"About to test the performance on the test set.\")\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "            if device.type=='cuda':\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            testLoss+=loss.item()\n",
    "            if(i%50==0):\n",
    "                if(i>0):\n",
    "                    print('Tested images:',i*testloader.batch_size,'. Running Timer @ {:.2f}sec.'.format(time.time()-t0))\n",
    "\n",
    "\n",
    "    train_epoch_losses.append(epochLoss/len(trainloader))\n",
    "    test_epoch_losses.append(testLoss/len(testloader))\n",
    "    EpochLength = time.time()-t0\n",
    "    print('{} train loss: {:.3f} and test loss: {:.3f}, and it took us: {:.2f} seconds.'.format (epoch + 1, epochLoss / len(trainloader),testLoss/len(testloader),EpochLength))  # DAVID CHanged it to 1000 from 2000 not sure if thats totally done\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post training analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training has finished, save information about the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the learnd model in file that can be loaded in for inference\n",
    "SpectrumVariables = pickle.load(open(os.path.join(SPECTRUM_IMAGES_CLASSES_TRAIN,'Main.SpecVar'), \"rb\" ) )\n",
    "torch.save({\n",
    "    'model':model.state_dict(),\n",
    "    'classes':classes,\n",
    "    'resolution':INPUT_RESOLUTION,\n",
    "    'SpectrumVariables':SpectrumVariables,\n",
    "    'modelType':\"resnet18\" # <= If you try out different models make sure to change this too\n",
    "},\"../models/CatDogResNet.pth\") # <=Edit file name here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display how the traing and test loss progressed over successive epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying how the loss progresses over time.\n",
    "plt.plot(train_epoch_losses, label='Training Loss',c='r')\n",
    "plt.plot(test_epoch_losses, label='Test Loss',c='g')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show spectagrams, Predicted and Actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print predicted and acual labels for Spectragrams\n",
    "dataiter = iter(testloader)\n",
    "model.eval()\n",
    "for j in range (2):\n",
    "    images, labels = dataiter.next()\n",
    "    if device == 'cuda':\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        imshow(images[i])\n",
    "        print('GroundTruth: ',classes[labels[i]])\n",
    "        print('Predicted: ',  classes[predicted[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print accuracy of test predictions for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network analytics\n",
    "class_correct = list(0. for i in range(len(classes)))\n",
    "class_total = list(0. for i in range(len(classes)))\n",
    "model.eval()\n",
    "allLabels=[]\n",
    "allPrediction=[]\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        if (c.dim()==0):\n",
    "            continue\n",
    "        for i in range(testloader.batch_size):\n",
    "            if(len(labels)<=i):\n",
    "                continue;\n",
    "            label = labels[i]\n",
    "            allLabels.append(labels[i].to('cpu').numpy())\n",
    "            allPrediction.append(predicted[i].to('cpu').numpy())\n",
    "            #print (c.shape)\n",
    "            if(testloader.batch_size>1):\n",
    "\n",
    "                class_correct[label] += c[i].item()\n",
    "            else:\n",
    "                class_correct[label] += c.item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "print(confusion_matrix(allLabels, allPrediction))\n",
    "for i in range(len(classes)):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
